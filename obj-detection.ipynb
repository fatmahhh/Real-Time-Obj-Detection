{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T10:41:03.707890Z",
     "start_time": "2022-08-16T10:41:01.539323Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import yolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T10:43:16.740091Z",
     "start_time": "2022-08-16T10:43:15.240027Z"
    }
   },
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# names of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T10:46:19.200042Z",
     "start_time": "2022-08-16T10:46:19.179058Z"
    }
   },
   "outputs": [],
   "source": [
    "classes=[]\n",
    "with open(\"names.txt\", \"r\") as txt_file:\n",
    "    classes =txt_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T10:46:20.753998Z",
     "start_time": "2022-08-16T10:46:20.732015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorbike',\n",
       " 'aeroplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'sofa',\n",
       " 'pottedplant',\n",
       " 'bed',\n",
       " 'diningtable',\n",
       " 'toilet',\n",
       " 'tvmonitor',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lading target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:14:27.580340Z",
     "start_time": "2022-08-16T11:14:27.542364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275, 183, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"download.jpg\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:14:28.203353Z",
     "start_time": "2022-08-16T11:14:28.183368Z"
    }
   },
   "outputs": [],
   "source": [
    "height, width, channels = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:14:28.827054Z",
     "start_time": "2022-08-16T11:14:28.808068Z"
    }
   },
   "outputs": [],
   "source": [
    "#the format which their deep learning models accepts as its inputs\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect obj in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:14:31.578194Z",
     "start_time": "2022-08-16T11:14:29.881178Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the input from the blob into the network\n",
    "net.setInput(blob)\n",
    "# get the output layers names\n",
    "output_layers_names = net.getUnconnectedOutLayersNames() \n",
    "## passing output layers names to forward network\n",
    "layersOutput = net.forward(output_layers_names) \n",
    "boundary_boxes = []\n",
    "probabilities = []\n",
    "predicted_classes = []\n",
    "for output in layersOutput: # extract all the information from the layers output\n",
    "    for detection in output: # extract the information from each of the outputs\n",
    "        scores = detection[5:] # store all the acting classes predictions \n",
    "        class_id = np.argmax(scores) # store the locations that contains the higher scores\n",
    "        probability = scores[class_id] # extract the higher scores,\n",
    "        # bec. we want to make sure that thier their predictions has a confidence that is high enough to consider that the object has been detected\n",
    "        if probability > 0.5:\n",
    "            center_x = int(detection[0]*width) # scale it back\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            # bec. yolo predicts the results with the center of the bounding boxes\n",
    "            # extract the upper left cornor position\n",
    "            x = int(center_x- w/2)\n",
    "            y = int(center_y- h/2)\n",
    "            boundary_boxes.append([x,y,w,h])\n",
    "            probabilities.append((float(probability)))\n",
    "            predicted_classes.append(class_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMS handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:14:32.419707Z",
     "start_time": "2022-08-16T11:14:32.410715Z"
    }
   },
   "outputs": [],
   "source": [
    "indexes = cv2.dnn.NMSBoxes(boundary_boxes, probabilities, 0.5, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:14:33.014668Z",
     "start_time": "2022-08-16T11:14:33.000680Z"
    }
   },
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boundary_boxes), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Draw Boundary Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:15:04.669917Z",
     "start_time": "2022-08-16T11:14:34.154415Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in indexes.flatten():\n",
    "    x,y,w,h = boundary_boxes[i]\n",
    "    label = str(classes[predicted_classes[i]])\n",
    "    probability = str(round(probabilities[i], 2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(img, label + \" \" + probability, (x, y+20), font, 2, (0,255,0), 2)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Vedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:21:32.067633Z",
     "start_time": "2022-08-16T11:20:16.013151Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture('video_preview_h264.mp4')\n",
    "while True:\n",
    "    _, img = vid.read()\n",
    "    height, width, channels = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob) # set the input from the blob into the network\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames() # get the output layers names\n",
    "    layersOutput = net.forward(output_layers_names) # passing output layers names to forward network function we will get the output from this funciton\n",
    "    boundary_boxes = []\n",
    "    probabilities = []\n",
    "    predicted_classes = []\n",
    "    for output in layersOutput: # extract all the information from the layers output\n",
    "        for detection in output: # extract the information from each of the outputs\n",
    "            scores = detection[5:] # store all the acting classes predictions \n",
    "            class_id = np.argmax(scores) # store the locations that contains the higher scores\n",
    "            probability = scores[class_id] # extract the higher scores,\n",
    "            # bec. we want to make sure that thier their predictions has a confidence that is high enough to consider that the object has been detected\n",
    "            if probability > 0.5:\n",
    "                center_x = int(detection[0]*width) # scale it back\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "                # bec. yolo predicts the results with the center of the bounding boxes\n",
    "                # extract the upper left cornor position\n",
    "                x = int(center_x- w/2)\n",
    "                y = int(center_y- h/2)\n",
    "                boundary_boxes.append([x,y,w,h])\n",
    "                probabilities.append((float(probability)))\n",
    "                predicted_classes.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boundary_boxes, probabilities, 0.5, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boundary_boxes), 3))\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boundary_boxes[i]\n",
    "            label = str(classes[predicted_classes[i]])\n",
    "            probability = str(round(probabilities[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + probability, (x, y+20), font, 2, (255,255,255), 2)\n",
    "    cv2.imshow('Image', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect in WEBCAMERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:22:26.468916Z",
     "start_time": "2022-08-16T11:22:14.317463Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-35a224d91d6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m416\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m416\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswapRB\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# set the input from the blob into the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, img = vid.read()\n",
    "    height, width, channels = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob) # set the input from the blob into the network\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames() # get the output layers names\n",
    "    layersOutput = net.forward(output_layers_names) # passing output layers names to forward network function we will get the output from this funciton\n",
    "    boundary_boxes = []\n",
    "    probabilities = []\n",
    "    predicted_classes = []\n",
    "    for output in layersOutput: # extract all the information from the layers output\n",
    "        for detection in output: # extract the information from each of the outputs\n",
    "            scores = detection[5:] # store all the acting classes predictions \n",
    "            class_id = np.argmax(scores) # store the locations that contains the higher scores\n",
    "            probability = scores[class_id] # extract the higher scores,\n",
    "            # bec. we want to make sure that thier their predictions has a confidence that is high enough to consider that the object has been detected\n",
    "            if probability > 0.5:\n",
    "                center_x = int(detection[0]*width) # scale it back\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "                # bec. yolo predicts the results with the center of the bounding boxes\n",
    "                # extract the upper left cornor position\n",
    "                x = int(center_x- w/2)\n",
    "                y = int(center_y- h/2)\n",
    "                boundary_boxes.append([x,y,w,h])\n",
    "                probabilities.append((float(probability)))\n",
    "                predicted_classes.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boundary_boxes, probabilities, 0.5, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boundary_boxes), 3))\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boundary_boxes[i]\n",
    "            label = str(classes[predicted_classes[i]])\n",
    "            probability = str(round(probabilities[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + probability, (x, y+20), font, 2, (255,255,255), 2)\n",
    "    cv2.imshow('Image', img)\n",
    "    key = cv2.waitKey(100)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
